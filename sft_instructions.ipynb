{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  5 19:01:38 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:4E:00.0 Off |                    0 |\n",
      "| N/A   34C    P0             85W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "num_workers = os.cpu_count()\n",
    "# max_steps = 3000\n",
    "bf16 = True\n",
    "fp16 = False\n",
    "# gradient_accumulation_steps = 2\n",
    "context_length = 1024\n",
    "logging_steps = 500\n",
    "save_steps = 500\n",
    "learning_rate = 2e-4\n",
    "model_name = './custom_gpt2'\n",
    "out_dir = 'outputs/gpt2_sft_instruction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'text'],\n",
      "        num_rows: 52002\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_alpaca = load_dataset('tatsu-lab/alpaca')\n",
    "print(dataset_alpaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_rlhf = load_dataset('Anthropic/hh-rlhf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['chosen', 'rejected'],\n",
      "        num_rows: 160800\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['chosen', 'rejected'],\n",
      "        num_rows: 8552\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(hh_rlhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    # alpaca\n",
    "    if 'instruction' in example:\n",
    "        text = f\"Human:\\n{example['instruction']}\"\n",
    "        if len(example['input'].strip())>0: \n",
    "            text+=f\"\\ninput -\\n{example['input']}\"\n",
    "        text+=f\"\\n\\nAssistant:\\n{example['output']}\"\n",
    "    else:\n",
    "        text = example['chosen'].strip().replace(\"Human:\", \"<|endoftext|>Human:\").removeprefix('<|endoftext|>').removesuffix('<|endoftext|>')\n",
    "\n",
    "        \n",
    "    \n",
    "    return {\"input_text\":text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_alpaca = dataset_alpaca.map(preprocess_function).remove_columns(['instruction', 'input', 'output', 'text'])['train'].train_test_split(test_size=0.05, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_text'],\n",
       "        num_rows: 49401\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_text'],\n",
       "        num_rows: 2601\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_text'],\n",
      "    num_rows: 49401\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_text'],\n",
      "    num_rows: 2601\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_train_alpaca = full_dataset_alpaca['train']\n",
    "dataset_valid_alpaca = full_dataset_alpaca['test']\n",
    "\n",
    "print(dataset_train_alpaca)\n",
    "print(dataset_valid_alpaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_text'],\n",
       "        num_rows: 76380\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_text'],\n",
       "        num_rows: 4020\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_dataset_hh_rlhf = hh_rlhf['train'].train_test_split(test_size=0.5, shuffle=True, seed=42)['train'].map(preprocess_function).remove_columns(['chosen', 'rejected']).train_test_split(test_size=0.05, shuffle=True, seed=42)\n",
    "half_dataset_hh_rlhf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_text'],\n",
      "    num_rows: 76380\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_text'],\n",
      "    num_rows: 4020\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_train_hh_rlhf = half_dataset_hh_rlhf['train']\n",
    "dataset_valid_hh_rlhf = half_dataset_hh_rlhf['test']\n",
    " \n",
    "print(dataset_train_hh_rlhf)\n",
    "print(dataset_valid_hh_rlhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset_train = concatenate_datasets([dataset_train_alpaca, dataset_train_hh_rlhf]).shuffle(seed=42)\n",
    "combined_dataset_val = concatenate_datasets([dataset_valid_alpaca, dataset_valid_hh_rlhf]).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_text'],\n",
      "    num_rows: 125781\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_text'],\n",
      "    num_rows: 6621\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset_train)\n",
    "print(combined_dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bf16:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to(dtype=torch.bfloat16)\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{out_dir}/logs\",\n",
    "    evaluation_strategy='steps',\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    logging_steps=logging_steps,\n",
    "    save_steps=save_steps,\n",
    "    save_total_limit=3,\n",
    "    bf16=bf16,\n",
    "    fp16=fp16,\n",
    "    # report_to='tensorboard',\n",
    "    num_train_epochs=3,\n",
    "    dataloader_num_workers=num_workers,\n",
    "    # gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    # lr_scheduler_type='constant',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=combined_dataset_train,\n",
    "    eval_dataset=combined_dataset_val,\n",
    "    dataset_text_field=\"input_text\",\n",
    "    max_seq_length=context_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    # packing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpandraju-s\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240805_190205-swd59jze</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pandraju-s/huggingface/runs/swd59jze' target=\"_blank\">outputs/gpt2_sft_instruction/logs</a></strong> to <a href='https://wandb.ai/pandraju-s/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pandraju-s/huggingface' target=\"_blank\">https://wandb.ai/pandraju-s/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pandraju-s/huggingface/runs/swd59jze' target=\"_blank\">https://wandb.ai/pandraju-s/huggingface/runs/swd59jze</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9435' max='9435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9435/9435 1:26:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.794600</td>\n",
       "      <td>2.503538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.632100</td>\n",
       "      <td>2.460795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.599200</td>\n",
       "      <td>2.450081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.596000</td>\n",
       "      <td>2.445371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.594300</td>\n",
       "      <td>2.442328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.582700</td>\n",
       "      <td>2.441772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.588200</td>\n",
       "      <td>2.441024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.584800</td>\n",
       "      <td>2.440697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.586700</td>\n",
       "      <td>2.440515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.577000</td>\n",
       "      <td>2.440104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.590500</td>\n",
       "      <td>2.440098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.584700</td>\n",
       "      <td>2.440485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.589800</td>\n",
       "      <td>2.440107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.585600</td>\n",
       "      <td>2.440402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.584200</td>\n",
       "      <td>2.440309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.586000</td>\n",
       "      <td>2.440194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.584800</td>\n",
       "      <td>2.440104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.589700</td>\n",
       "      <td>2.439848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9435, training_loss=2.6009724093923885, metrics={'train_runtime': 5198.6918, 'train_samples_per_second': 72.584, 'train_steps_per_second': 1.815, 'total_flos': 1.33019273348352e+17, 'train_loss': 2.6009724093923885, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('outputs/gpt2_sft_instruction/final_model/tokenizer_config.json',\n",
       " 'outputs/gpt2_sft_instruction/final_model/special_tokens_map.json',\n",
       " 'outputs/gpt2_sft_instruction/final_model/vocab.json',\n",
       " 'outputs/gpt2_sft_instruction/final_model/merges.txt',\n",
       " 'outputs/gpt2_sft_instruction/final_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(f\"{out_dir}/final_model\")\n",
    "tokenizer.save_pretrained(f\"{out_dir}/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModelForCausalLM.from_pretrained('outputs/gpt2_sft_instruction/final_model/')\n",
    "tokenizer = AutoTokenizer.from_pretrained('outputs/gpt2_sft_instruction/final_model/')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task='text-generation', \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=1024, # Prompt + new tokens to generate.\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_pipe = pipeline(\n",
    "    task='text-generation', \n",
    "    model=og_model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=1024, # Prompt + new tokens to generate.\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Human:\n",
    "{}\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format(\"Can you tell me what are the best places to visit in India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:\n",
      "Can you tell me what are the best places to visit in India?\n",
      "\n",
      "Assistant:\n",
      "-If we go on a tour, it would be easy. It is not something that can make us feel like an ordinary person but there must have been people who were very interesting and knowledgeable about how things work here so I think this has always got some appeal over time as well.\"\n",
      "'What was your most important decision for being away from home?' â€“ Vadodara's question\n",
      "\n",
      " \"I wanted to travel with my family because of our great job at Aam Aadmi Party (AAP) which started working out after 2000 when one member said 'It seems difficult doing jobs'. Even if they didn't want to do any sort Of course no such thing could happenâ€¦ But everything changed then too!\" â€”Vadoda Kaur\n"
     ]
    }
   ],
   "source": [
    "outputs = og_pipe(\n",
    "    prompt, \n",
    "    do_sample=True, \n",
    "    temperature=0.7, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:\n",
      "Can you tell me what are the best places to visit in India?\n",
      "\n",
      "Assistant:\n",
      "Indian cities offer a number of unique experiences. Many Indian cultural destinations, such as Gurgaon, Delhi, Mumbai and Lucknow, all boast stunning views of nature and magnificent architecture. They also provide opportunities for local businesses with abundant resources including shops, restaurants (both traditional and modern), public transport, electricity, health care facilities, medical services, schools, entertainment venues etc. Some popular tourist attractions include Bhutanese temples or Chola-Tibetan shrines; Sri Lanka's beautiful green fields; Rajasthan's great river valley ; Nepal's Himalayan mountains; Kenya's spectacular mountain ranges; Japan, Vietnam's famous coastal city Hanoi; Indonesia's legendary island nation. You can find many more options than just one destination!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(\n",
    "    prompt, \n",
    "    do_sample=True, \n",
    "    temperature=0.7, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
